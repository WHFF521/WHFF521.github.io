<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>AiRomance</title>
  <icon>https://blog.whff521.xyz/images/101.ico</icon>
  <subtitle>爱裸漫三三</subtitle>
  <link href="https://blog.whff521.xyz/atom.xml" rel="self"/>
  <link href="https://pubsubhubbub.appspot.com/" rel="hub"/>
  <link href="https://blog.whff521.xyz/"/>
  <updated>2025-07-22T07:06:20.831Z</updated>
  <id>https://blog.whff521.xyz/</id>
  
  <author>
    <name>AiRomance</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kaggle 离线使用YOLOv5——Global Wheat Detection</title>
    <link href="https://blog.whff521.xyz/2025/07/22/Kaggle-%E7%A6%BB%E7%BA%BF%E4%BD%BF%E7%94%A8YOLOv5%E2%80%94%E2%80%94Global-Wheat-Detection/"/>
    <id>https://blog.whff521.xyz/2025/07/22/Kaggle-%E7%A6%BB%E7%BA%BF%E4%BD%BF%E7%94%A8YOLOv5%E2%80%94%E2%80%94Global-Wheat-Detection/</id>
    <published>2025-07-22T05:40:14.000Z</published>
    <updated>2025-07-22T07:06:20.831Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Kaggle-离线使用YOLOv5——Global-Wheat-Detection"><a href="#Kaggle-离线使用YOLOv5——Global-Wheat-Detection" class="headerlink" title="Kaggle 离线使用YOLOv5——Global Wheat Detection"></a>Kaggle 离线使用YOLOv5——Global Wheat Detection</h1><p>Kaggle上很多比赛都要求代码在离线（offline）状态下运行的，虽然notebook的运行环境已经自带了很多深度学习和神经网络的包，但是要运行GitHub上下载的YOLOv5模型还差一些包和环境需求导致不能直接运行。而且离线状态下也不允许使用<code>git</code>命令克隆仓库。</p><p>那我直接上传最终<code>submission.csv</code>不就行了？很遗憾不行的。因为最终分数会扩大测试数据重新测试你代码运行的结果，这其实也是为什么要offline的原因，防止有人利用网络将扩大的数据集传出来以致于不公平。</p><p>我本来是想用<a href="https://www.kaggle.com/competitions/global-wheat-detection">Global Wheat Detection</a>练习一下YOLOv5的使用，但是因为离线环境确实困扰了我几天的时间。我对Kaggle的notebook到底是怎么运作的并不清楚，而且网上鲜有这样的教程。网络上搜不到答案只有两种情况：一是这真的很难，没有人能做出来（我的问题当然不是这种情况）；<strong>二是答案很简单，不值得出教程（事实确实是这样）</strong>。不过还是在此记录一下我是怎么实现的吧</p><h2 id="Notebook环境说明"><a href="#Notebook环境说明" class="headerlink" title="Notebook环境说明"></a>Notebook环境说明</h2><p>Kaggle的Notebook实际上是一个<code>.ipynb</code>编辑器，支持code和markdown两种语言进行编写，我们可以分段编写和运行代码。因为notebook能持续保持运行状态，可以一块一块地执行代码，且前面的执行结果和变量依然有效。</p><p>设置可以更改运行是否使用GPU，这里需要注意，要在代码运行之前就进行选择，因为更换GPU不是热加载，而是直接更换一个新的运行环境，之前运行的环境会丢失。</p><p>右边<code>sidebar</code>（如果没有在<code>view</code>里点击<code>show sidebar</code>）可以加载数据集。如果你是在比赛的<code>code</code>页面点击的<code>new notebook</code>，那么可以看到<code>input</code>自动加载了这场比赛的数据集。</p><p>可以自行添加数据到<code>input</code>里面，有两种方式：一是从网站已有的数据进行添加，比如其他比赛的数据集，或者是你自己其他notebook上的产出文件（Output）；二是从自己电脑上传压缩包文件，上传的时候会询问是model还是dataset，其实还是第一种方式加载数据，你上传的文件会先保存到网站上，然后再加载。你上传的压缩文件会自动解压到当前环境的<code>input</code>目录下。</p><p>注意，所有notebook都有两个路径可以使用，一是<code>/kaggle/input/</code>,这个是存放所有准备使用的文件的，这个文件夹只读，不能更改；二是<code>/kaggle/working/</code>，这个文件夹是你代码所有产出保存文件的地址，这个文件夹没有只读的限制，可以随意更改，但是有上限20GB的要求。在运行<code>Save&amp;Run All(Commit)</code>保存这个版本的Version的时候，Kaggle会自动从头到尾运行代码，而且保存这个notebook的<code>/kaggle/working/</code>下的所有文件。当你在新notebook里面，可以添加这个notebook的output，会保存在新notebook的<code>/kaggle/input/</code>的文件夹下。</p><p>建议先将所有文件复制到<code>working</code>文件夹下在进行其他操作，处理数据会比较方便。</p><h2 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h2><p>因为是边试错边完成的，所以步骤有些冗余。</p><p>我一共创建了三个notebook和一个dataset。notebook分别是<code>YOLOv5&amp;Dependences</code>,<code>WheatDetectOffineTrain</code>和<code>WheatDetectOfflineDetect</code>。一个数据集是<code>ArialTTF</code>,其实就是Arial字体文件。</p><p>这里强调一下，模型的训练和检测建议分成两个notebook来写，因为提交之后会运行你的代码，如果重新训练的话会花费大量的时间才能得到分数。</p><h3 id="ArialTTF"><a href="#ArialTTF" class="headerlink" title="ArialTTF"></a>ArialTTF</h3><p>先说一下这个数据集吧，这是在用YOLOv5训练的时候报错发现的，它说没有Arial字体文件。因为YOLOv5训练结束后会展示一些图片，上面会画框和标注标签，需要字体文件。Arial应该是最基本的英文字体文件了，然而Kaggle环境里并没有，所以需要在input加上这个字体文件，下面会提到怎么处理这个字体文件。</p><p>创建方法很简单，在notebook编辑页面点击上传input，选择dataset，上传在网上下载好的字体文件即可。</p><h3 id="YOLOv5-amp-Dependences"><a href="#YOLOv5-amp-Dependences" class="headerlink" title="YOLOv5&amp;Dependences"></a>YOLOv5&amp;Dependences</h3><p>这个notebook可以连接网络。其实只有最后提交的notebook offline就行。。。。。。。。。。。。。。。。。</p><p>WTF，WTF，WTF。。。。。。</p><p>所以我为什么要写三个notebook，我为什么要在train的时候也离线了。。。</p><p>我真的是写到这里的时候才意识到这个问题。</p><p>因为当前这个<code>YOLOv5&amp;Dependences</code> notebook主要解决的是离线notebook不能使用git,pip命令进行在线操作的问题。我想的是在这里下载好YOLOv5和依赖包之后，在<code>WheatDetectOffineTrain</code>里面作为input进行加载就可以离线使用YOLOv5了。</p><p>实际上<code>WheatDetectOffineTrain</code>完全可以联网下载和安装依赖，所以这个notebook完全没有存在的必要。</p><p>我终于明白discussion里面有人说的你需要创建两个notebook，一个用来训练，一个用来检测是什么意思了。并不是需要，而是“只”需要两个。</p><p>不过还是记录一下这个notebook的代码吧：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">!git clone https://github.com/ultralytics/yolov5</span><br><span class="line"><span class="meta prompt_">%</span><span class="language-bash"><span class="built_in">cd</span> yolov5</span></span><br><span class="line">!pip download -r requirements.txt -d dependences</span><br><span class="line">!mkdir -p weights</span><br><span class="line">!wget -P weights https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt</span><br></pre></td></tr></table></figure><p>因为预训练文件是在线加载的，所以也得提前下载。。。</p><h3 id="WheatDetectOffineTrain"><a href="#WheatDetectOffineTrain" class="headerlink" title="WheatDetectOffineTrain"></a>WheatDetectOffineTrain</h3><p>好，接下来记录一下这个“离线”训练的notebook。</p><p>首先要先添加input，将上面两个加载进来。</p><p>然后安装依赖：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install --no-index --find-links=/kaggle/input/yolov5-dependences/yolov5/dependences -r /kaggle/input/yolov5-dependences/yolov5/requirements.txt</span><br></pre></td></tr></table></figure></p><p>这里运行完后会看见报错：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ERROR: pip&#x27;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.</span><br><span class="line">torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.</span><br><span class="line">fastai 2.7.19 requires torch&lt;2.7,&gt;=1.10, but you have torch 2.7.1 which is incompatible.</span><br></pre></td></tr></table></figure><br>好像是因为本地torch版本太高了，不过不用理会，代码能正常运行。</p><p>创建数据集文件夹<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.makedirs(<span class="string">&#x27;/kaggle/working/wheat&#x27;</span>, exist_ok=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p><p>将标签转换成YOLO格式：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment"># set path</span></span><br><span class="line">csv_path = <span class="string">r&#x27;/kaggle/input/global-wheat-detection/train.csv&#x27;</span></span><br><span class="line">image_dir = <span class="string">r&#x27;/kaggle/input/global-wheat-detection/train&#x27;</span></span><br><span class="line">label_output_dir = <span class="string">r&#x27;/kaggle/working/wheat/labels&#x27;</span></span><br><span class="line"></span><br><span class="line">os.makedirs(label_output_dir,exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(csv_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解析 bbox 字符串为 float 类型的 [x, y, w, h]</span></span><br><span class="line">df[[<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, <span class="string">&#x27;h&#x27;</span>]] = df[<span class="string">&#x27;bbox&#x27;</span>].apply(<span class="keyword">lambda</span> x: <span class="built_in">eval</span>(x)).apply(pd.Series)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">convert_bbox_to_yolo</span>(<span class="params">size,box</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    size: (width,height)</span></span><br><span class="line"><span class="string">    box: (x_min, y_min, width, height)</span></span><br><span class="line"><span class="string">    return: normalized (x_center, y_center, width, height)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dw, dh = <span class="number">1.</span> / size[<span class="number">0</span>], <span class="number">1.</span> / size[<span class="number">1</span>]</span><br><span class="line">    x_center = (box[<span class="number">0</span>] + box[<span class="number">2</span>] / <span class="number">2.0</span>) * dw</span><br><span class="line">    y_center = (box[<span class="number">1</span>] + box[<span class="number">3</span>] / <span class="number">2.0</span>) * dh</span><br><span class="line">    w = box[<span class="number">2</span>] * dw</span><br><span class="line">    h = box[<span class="number">3</span>] * dh</span><br><span class="line">    <span class="keyword">return</span> x_center, y_center, w, h</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> image_id, group <span class="keyword">in</span> tqdm(df.groupby(<span class="string">&#x27;image_id&#x27;</span>), desc=<span class="string">&quot;Generating labels&quot;</span>):</span><br><span class="line">    image_path = os.path.join(image_dir,image_id + <span class="string">&#x27;.jpg&#x27;</span>)</span><br><span class="line">    label_path = os.path.join(label_output_dir, image_id + <span class="string">&#x27;.txt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(image_path):</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">with</span> Image.<span class="built_in">open</span>(image_path) <span class="keyword">as</span> img:</span><br><span class="line">        img_w, img_h = img.size</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(label_path,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> _, row <span class="keyword">in</span> group.iterrows():</span><br><span class="line">            x_center, y_center, w, h = convert_bbox_to_yolo((img_w, img_h), (row[<span class="string">&#x27;x&#x27;</span>], row[<span class="string">&#x27;y&#x27;</span>], row[<span class="string">&#x27;w&#x27;</span>], row[<span class="string">&#x27;h&#x27;</span>]))</span><br><span class="line">            f.write(<span class="string">f&quot;0 <span class="subst">&#123;x_center:<span class="number">.6</span>f&#125;</span> <span class="subst">&#123;y_center:<span class="number">.6</span>f&#125;</span> <span class="subst">&#123;w:<span class="number">.6</span>f&#125;</span> <span class="subst">&#123;h:<span class="number">.6</span>f&#125;</span>\n&quot;</span>)</span><br></pre></td></tr></table></figure></p><p>输出：<code>Generating labels: 100%|██████████| 3373/3373 [00:23&lt;00:00, 144.72it/s]</code></p><p>整理图像文件夹，符合YOLO要求，划分训练集验证集。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line">image_dir = Path(<span class="string">r&#x27;/kaggle/input/global-wheat-detection/train&#x27;</span>)</span><br><span class="line">label_dir = Path(<span class="string">r&#x27;/kaggle/working/wheat/labels&#x27;</span>)</span><br><span class="line">output_base = Path(<span class="string">r&#x27;/kaggle/working/wheat/yolo&#x27;</span>)</span><br><span class="line"></span><br><span class="line">os.makedirs(output_base,exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train_ratio = <span class="number">0.8</span></span><br><span class="line"></span><br><span class="line">output_images_train = output_base / <span class="string">&#x27;images/train&#x27;</span></span><br><span class="line">output_images_val = output_base / <span class="string">&#x27;images/val&#x27;</span></span><br><span class="line">output_labels_train = output_base / <span class="string">&#x27;labels/train&#x27;</span></span><br><span class="line">output_labels_val = output_base / <span class="string">&#x27;labels/val&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建目标文件夹</span></span><br><span class="line"><span class="keyword">for</span> path <span class="keyword">in</span> [output_images_train, output_images_val, output_labels_train, output_labels_val]:</span><br><span class="line">    os.makedirs(path, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">image_files = <span class="built_in">list</span>(image_dir.glob(<span class="string">&#x27;*.jpg&#x27;</span>))</span><br><span class="line"><span class="comment"># stem is to remove .jpg</span></span><br><span class="line">image_ids = [img.stem <span class="keyword">for</span> img <span class="keyword">in</span> image_files] </span><br><span class="line"></span><br><span class="line">random.seed(<span class="number">42</span>)</span><br><span class="line">random.shuffle(image_ids)</span><br><span class="line"></span><br><span class="line">split_index = <span class="built_in">int</span>(<span class="built_in">len</span>(image_ids) * train_ratio)</span><br><span class="line">train_ids = image_ids[:split_index]</span><br><span class="line">val_ids = image_ids[split_index:]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">copy_files</span>(<span class="params">image_ids, image_dst, label_dst</span>):</span><br><span class="line">    <span class="keyword">for</span> image_id <span class="keyword">in</span> image_ids:</span><br><span class="line">        src_img = image_dir / <span class="string">f&quot;<span class="subst">&#123;image_id&#125;</span>.jpg&quot;</span></span><br><span class="line">        dst_img = image_dst / <span class="string">f&quot;<span class="subst">&#123;image_id&#125;</span>.jpg&quot;</span></span><br><span class="line">        shutil.copy2(src_img,dst_img)</span><br><span class="line"></span><br><span class="line">        src_label = label_dir / <span class="string">f&quot;<span class="subst">&#123;image_id&#125;</span>.txt&quot;</span></span><br><span class="line">        dst_label = label_dst / <span class="string">f&quot;<span class="subst">&#123;image_id&#125;</span>.txt&quot;</span></span><br><span class="line">        <span class="keyword">if</span> src_label.exists():</span><br><span class="line">            shutil.copy2(src_label, dst_label)</span><br><span class="line">        <span class="keyword">else</span>: </span><br><span class="line">            dst_label.write_text(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">copy_files(train_ids, output_images_train,output_labels_train)</span><br><span class="line">copy_files(val_ids, output_images_val,output_labels_val)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;✅ 划分完成：<span class="subst">&#123;<span class="built_in">len</span>(train_ids)&#125;</span> 张用于训练，<span class="subst">&#123;<span class="built_in">len</span>(val_ids)&#125;</span> 张用于验证。&quot;</span>)</span><br></pre></td></tr></table></figure></p><p>输出：<code>✅ 划分完成：2737 张用于训练，685 张用于验证。</code></p><p><strong>注意：没有框的图片也需要一个对应的空txt文件</strong></p><p>编写yaml文件：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">yaml_content = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">path: /kaggle/working/wheat/yolo</span></span><br><span class="line"><span class="string">train: images/train</span></span><br><span class="line"><span class="string">val: images/val</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">nc: 1</span></span><br><span class="line"><span class="string">names: [&#x27;wheat&#x27;]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;wheat.yaml&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(yaml_content)</span><br></pre></td></tr></table></figure></p><p>将YOLOv5拷贝到working文件夹：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!cp -r /kaggle/input/yolov5-dependences/yolov5 /kaggle/working/yolov5</span><br></pre></td></tr></table></figure><p>因为YOLOv5在运行的时候wandb会联网进行git检查，然而当前是offline的，会造成无法运行的情况。这里使用了chatgpt教我的“猴子戏法”，将执行检查的函数无效化：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> types</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&#x27;/kaggle/working/yolov5&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> utils.general <span class="keyword">as</span> general</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dummy_check_git_info</span>():</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;unknown&#x27;</span></span><br><span class="line"></span><br><span class="line">general.check_git_info = dummy_check_git_info</span><br></pre></td></tr></table></figure><p>安装字体文件,我们只需要将字体文件移动到yolo会寻找字体的地方即可：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!mkdir -p /root/.config/Ultralytics/</span><br><span class="line">!cp /kaggle/input/arialttf/Arial.ttf /root/.config/Ultralytics/Arial.ttf</span><br></pre></td></tr></table></figure><p>执行训练命令，这里先进入到YOLO文件夹下，简化命令：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">%</span><span class="language-bash"><span class="built_in">cd</span> /kaggle/working/yolov5/</span></span><br><span class="line">!python train.py --img 640 --batch 16 --epochs 50 --data /kaggle/working/wheat.yaml --weights weights/yolov5s.pt --name wheat_yolov5</span><br></pre></td></tr></table></figure></p><p>到此就可以了，执行<code>Save &amp; Run All(commit)</code>等待训练完成后就可以进行检测了。我并没有进行图片增强，增加数据集的操作而直接训练的，所以最后检测结果会有一点低。</p><h3 id="WheatDetectOfflineDetect"><a href="#WheatDetectOfflineDetect" class="headerlink" title="WheatDetectOfflineDetect"></a>WheatDetectOfflineDetect</h3><p>提前加载字体文件，<code>YOLOv5&amp;Dependences</code>和<code>WheatDetectOffineTrain</code>的output。</p><p>突然意识到<code>YOLOv5&amp;Dependences</code>也还是有一点存在的必要的，检测文件也需要安装环境，虽然说在训练文件里也可以下载。</p><p>安装依赖：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install --no-index --find-links=/kaggle/input/yolov5-dependences/yolov5/dependences -r /kaggle/input/yolov5-dependences/yolov5/requirements.txt</span><br></pre></td></tr></table></figure></p><p>拷贝训练后的YOLOv5文件夹：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!cp -r /kaggle/input/wheatdetectoffinetrain/yolov5 /kaggle/working/yolov5</span><br></pre></td></tr></table></figure><br>这时yolov5项目文件夹里是有训练后的<code>runs</code>文件夹的。</p><p>安装字体：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!mkdir -p /root/.config/Ultralytics/</span><br><span class="line">!cp /kaggle/input/arialttf/Arial.ttf /root/.config/Ultralytics/Arial.ttf</span><br></pre></td></tr></table></figure></p><p>转换工作目录：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">%</span><span class="language-bash"><span class="built_in">cd</span> /kaggle/working/yolov5/</span></span><br></pre></td></tr></table></figure></p><p>检测命令：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!python detect.py --weights runs/train/wheat_yolov5/weights/best.pt --source /kaggle/input/global-wheat-detection/test --img 640 --conf 0.25 --save-txt --save-conf --project runs/predict --name wheat_test</span><br></pre></td></tr></table></figure></p><p>这里说明一下，<code>--conf</code>是保留置信度，<code>--save-txt</code>是保存为txt文件。</p><p>转换yolo输出并生成<code>submission.csv</code>文件:</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 路径配置</span></span><br><span class="line">test_images_dir = Path(<span class="string">r&#x27;/kaggle/input/global-wheat-detection/test&#x27;</span>)</span><br><span class="line">pred_labels_dir = Path(<span class="string">r&#x27;/kaggle/working/yolov5/runs/predict/wheat_test/labels&#x27;</span>)</span><br><span class="line">submission_path = <span class="string">&#x27;/kaggle/working/submission.csv&#x27;</span></span><br><span class="line"></span><br><span class="line">results = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> image_path <span class="keyword">in</span> test_images_dir.glob(<span class="string">&#x27;*.jpg&#x27;</span>):</span><br><span class="line">    image_id = image_path.stem</span><br><span class="line">    label_path = pred_labels_dir / <span class="string">f&quot;<span class="subst">&#123;image_id&#125;</span>.txt&quot;</span></span><br><span class="line"></span><br><span class="line">    prediction_string = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> label_path.exists():</span><br><span class="line">        <span class="keyword">with</span> Image.<span class="built_in">open</span>(image_path) <span class="keyword">as</span> im:</span><br><span class="line">            img_w, img_h = im.size</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(label_path, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                parts = line.strip().split()</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(parts) == <span class="number">6</span>:</span><br><span class="line">                    cls, x_center, y_center, width, height, conf = <span class="built_in">map</span>(<span class="built_in">float</span>, parts)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 转回左上角坐标</span></span><br><span class="line">                    x_min = (x_center - width / <span class="number">2</span>) * img_w</span><br><span class="line">                    y_min = (y_center - height / <span class="number">2</span>) * img_h</span><br><span class="line">                    box_w = width * img_w</span><br><span class="line">                    box_h = height * img_h</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 拼接字符串：confidence x y w h</span></span><br><span class="line">                    prediction_string += <span class="string">f&quot;<span class="subst">&#123;conf:<span class="number">.4</span>f&#125;</span> <span class="subst">&#123;x_min:<span class="number">.1</span>f&#125;</span> <span class="subst">&#123;y_min:<span class="number">.1</span>f&#125;</span> <span class="subst">&#123;box_w:<span class="number">.1</span>f&#125;</span> <span class="subst">&#123;box_h:<span class="number">.1</span>f&#125;</span> &quot;</span></span><br><span class="line"></span><br><span class="line">    results.append(&#123;</span><br><span class="line">        <span class="string">&quot;image_id&quot;</span>: image_id,</span><br><span class="line">        <span class="string">&quot;PredictionString&quot;</span>: prediction_string.strip()</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存为 CSV</span></span><br><span class="line">df = pd.DataFrame(results)</span><br><span class="line">df.to_csv(submission_path, index=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;✅ 已保存提交文件: <span class="subst">&#123;submission_path&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>最终分数如下：<br><img src="https://images.whff521.top/Screenshot%202025-07-22%20at%2015.00.49.png" alt="分数"></p><p>虽然不是很高，但是在当年的排行榜上能排到第三的位置（感谢YOLO）</p><p>PS：封面图来源：<a href="https://x.com/nakiriayame/status/1946793366399918121?s=46"><br>百鬼あやめ😈ホロライブ2期生</a></p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;Kaggle-离线使用YOLOv5——Global-Wheat-Detection&quot;&gt;&lt;a href=&quot;#Kaggle-离线使用YOLOv5——Global-Wheat-Detection&quot; class=&quot;headerlink&quot; title=&quot;Kaggle</summary>
        
      
    
    
    
    <category term="深度学习" scheme="https://blog.whff521.xyz/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="yolo" scheme="https://blog.whff521.xyz/tags/yolo/"/>
    
    <category term="Kaggle" scheme="https://blog.whff521.xyz/tags/Kaggle/"/>
    
  </entry>
  
  <entry>
    <title>YOLOv5使用方法</title>
    <link href="https://blog.whff521.xyz/2025/07/21/YOLOv5%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"/>
    <id>https://blog.whff521.xyz/2025/07/21/YOLOv5%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</id>
    <published>2025-07-21T02:40:45.000Z</published>
    <updated>2025-07-21T03:25:42.145Z</updated>
    
    <content type="html"><![CDATA[<h1 id="YOLOv5使用方法"><a href="#YOLOv5使用方法" class="headerlink" title="YOLOv5使用方法"></a>YOLOv5使用方法</h1><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>YOLOv5 使用的数据集遵循的是 <strong>YOLO格式（YOLO annotation format）</strong>。以下是 YOLOv5 所需数据集的完整规范：</p><hr><h4 id="✅-1-目录结构"><a href="#✅-1-目录结构" class="headerlink" title="✅ 1. 目录结构"></a>✅ 1. <strong>目录结构</strong></h4><p>YOLOv5 通常的数据集结构如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">dataset/</span><br><span class="line">├── images/</span><br><span class="line">│   ├── train/</span><br><span class="line">│   │   ├── img1.jpg</span><br><span class="line">│   │   ├── img2.jpg</span><br><span class="line">│   ├── val/</span><br><span class="line">│   │   ├── img3.jpg</span><br><span class="line">│   │   ├── img4.jpg</span><br><span class="line">│</span><br><span class="line">├── labels/</span><br><span class="line">│   ├── train/</span><br><span class="line">│   │   ├── img1.txt</span><br><span class="line">│   │   ├── img2.txt</span><br><span class="line">│   ├── val/</span><br><span class="line">│   │   ├── img3.txt</span><br><span class="line">│   │   ├── img4.txt</span><br><span class="line">│</span><br><span class="line">└── data.yaml</span><br></pre></td></tr></table></figure><hr><h4 id="✅-2-标签文件格式（-txt）"><a href="#✅-2-标签文件格式（-txt）" class="headerlink" title="✅ 2. 标签文件格式（.txt）"></a>✅ 2. <strong>标签文件格式（<code>.txt</code>）</strong></h4><p>每张图像对应一个 <code>.txt</code> 文件，命名相同，内容如下格式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;class_id&gt; &lt;x_center&gt; &lt;y_center&gt; &lt;width&gt; &lt;height&gt;</span><br></pre></td></tr></table></figure><h5 id="坐标说明："><a href="#坐标说明：" class="headerlink" title="坐标说明："></a>坐标说明：</h5><ul><li><code>class_id</code>：整数，表示目标所属的类别，从0开始。</li><li><code>x_center</code>、<code>y_center</code>：目标中心的相对位置（范围是0~1，相对于图像宽度和高度）。</li><li><code>width</code>、<code>height</code>：目标框的相对宽度和高度（范围0~1）。</li></ul><p>例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 0.5 0.5 0.2 0.3</span><br></pre></td></tr></table></figure><p>表示第0类物体，其边界框中心在图像正中间，宽20%，高30%。</p><hr><h4 id="✅-3-data-yaml-文件格式"><a href="#✅-3-data-yaml-文件格式" class="headerlink" title="✅ 3. data.yaml 文件格式"></a>✅ 3. <strong><code>data.yaml</code> 文件格式</strong></h4><p>用于配置训练集、验证集、类别名等信息。例如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># path: ./dataset</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">images/train</span></span><br><span class="line"><span class="attr">val:</span> <span class="string">images/val</span></span><br><span class="line"><span class="comment"># test: ./dataset/images/test</span></span><br><span class="line"><span class="attr">nc:</span> <span class="number">3</span>  <span class="comment"># 类别数量</span></span><br><span class="line"><span class="attr">names:</span> [<span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;person&#x27;</span>]  <span class="comment"># 类别名称列表</span></span><br></pre></td></tr></table></figure><p>注释代表非必须字段，<code>path</code>指定后后面的路径只需写相对路径</p><hr><h4 id="✅-4-图片格式"><a href="#✅-4-图片格式" class="headerlink" title="✅ 4. 图片格式"></a>✅ 4. <strong>图片格式</strong></h4><ul><li>支持常见格式：<code>.jpg</code>, <code>.jpeg</code>, <code>.png</code></li><li>图片尺寸不必统一，但建议大小适中（训练时可自动resize）</li></ul><hr><h4 id="✅-5-常见注意事项"><a href="#✅-5-常见注意事项" class="headerlink" title="✅ 5. 常见注意事项"></a>✅ 5. <strong>常见注意事项</strong></h4><ul><li>标签文件中坐标必须是 <strong>归一化格式</strong>，即相对于图像宽高，范围在 <code>[0, 1]</code>。</li><li>每一行为一个标注框，<strong>没有标注的图像也必须有空的 <code>.txt</code> 文件</strong>。</li><li><code>images/train</code> 和 <code>labels/train</code> 中的文件名必须一一对应。</li></ul><hr><h4 id="✅-示例"><a href="#✅-示例" class="headerlink" title="✅ 示例"></a>✅ 示例</h4><p>假设有一张图像 <code>dog.jpg</code> 尺寸为 <code>800x600</code>，目标狗的位置是：</p><ul><li>左上角 <code>(x1=200, y1=150)</code></li><li>右下角 <code>(x2=600, y2=450)</code></li></ul><p>则：</p><ul><li><code>x_center = (200+600)/2 / 800 = 0.5</code></li><li><code>y_center = (150+450)/2 / 600 = 0.5</code></li><li><code>width = (600 - 200) / 800 = 0.5</code></li><li><code>height = (450 - 150) / 600 = 0.5</code></li></ul><p>标签行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1 0.5 0.5 0.5 0.5</span><br></pre></td></tr></table></figure><p>（假设“狗”的 <code>class_id=1</code>）</p><h2 id="配置文件说明"><a href="#配置文件说明" class="headerlink" title="配置文件说明"></a>配置文件说明</h2><p>YOLOv5 的配置文件主要包括以下几类，它们用于配置模型结构、训练过程、数据集路径等。下面是各类配置文件的说明：</p><hr><h4 id="🗂-1-data-yaml-—-数据集配置文件（训练-验证-测试路径-类别信息）"><a href="#🗂-1-data-yaml-—-数据集配置文件（训练-验证-测试路径-类别信息）" class="headerlink" title="🗂 1. data.yaml — 数据集配置文件（训练/验证/测试路径 + 类别信息）"></a>🗂 1. <code>data.yaml</code> — 数据集配置文件（<strong>训练/验证/测试路径 + 类别信息</strong>）</h4><p>位置：你自己创建或放在 <code>data/</code> 目录中</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示例</span></span><br><span class="line"><span class="attr">path:</span> <span class="string">../dataset</span>                 <span class="comment"># 数据集根路径（可选）</span></span><br><span class="line"><span class="attr">train:</span> <span class="string">images/train</span>              <span class="comment"># 训练图片路径（相对 path 或绝对路径）</span></span><br><span class="line"><span class="attr">val:</span> <span class="string">images/val</span>                  <span class="comment"># 验证图片路径</span></span><br><span class="line"><span class="attr">test:</span> <span class="string">images/test</span>                <span class="comment"># （可选）测试图片路径</span></span><br><span class="line"></span><br><span class="line"><span class="attr">nc:</span> <span class="number">3</span>                            <span class="comment"># 类别数量</span></span><br><span class="line"><span class="attr">names:</span> [<span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;person&#x27;</span>]  <span class="comment"># 类别名称列表</span></span><br></pre></td></tr></table></figure><hr><h4 id="📐-2-yaml-—-模型结构配置文件（模型架构与参数设置）"><a href="#📐-2-yaml-—-模型结构配置文件（模型架构与参数设置）" class="headerlink" title="📐 2. *.yaml — 模型结构配置文件（模型架构与参数设置）"></a>📐 2. <code>*.yaml</code> — 模型结构配置文件（<strong>模型架构与参数设置</strong>）</h4><p>位置：<code>models/</code> 目录下，常见如 <code>yolov5s.yaml</code>、<code>yolov5m.yaml</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yolov5s.yaml 示例</span></span><br><span class="line"><span class="attr">nc:</span> <span class="number">80</span>  <span class="comment"># 类别数，会在训练时被 data.yaml 中的 nc 覆盖</span></span><br><span class="line"><span class="attr">depth_multiple:</span> <span class="number">0.33</span>  <span class="comment"># 网络深度系数（层数缩放）</span></span><br><span class="line"><span class="attr">width_multiple:</span> <span class="number">0.50</span>  <span class="comment"># 通道宽度系数（通道数缩放）</span></span><br><span class="line"></span><br><span class="line"><span class="attr">anchors:</span></span><br><span class="line">  <span class="bullet">-</span> [<span class="number">10</span>,<span class="number">13</span>, <span class="number">16</span>,<span class="number">30</span>, <span class="number">33</span>,<span class="number">23</span>]  <span class="comment"># P3</span></span><br><span class="line">  <span class="bullet">-</span> [<span class="number">30</span>,<span class="number">61</span>, <span class="number">62</span>,<span class="number">45</span>, <span class="number">59</span>,<span class="number">119</span>] <span class="comment"># P4</span></span><br><span class="line">  <span class="bullet">-</span> [<span class="number">116</span>,<span class="number">90</span>, <span class="number">156</span>,<span class="number">198</span>, <span class="number">373</span>,<span class="number">326</span>] <span class="comment"># P5</span></span><br><span class="line"></span><br><span class="line"><span class="attr">backbone:</span></span><br><span class="line">  [[<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Focus</span>, [<span class="number">64</span>, <span class="number">3</span>]],</span><br><span class="line">   [<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Conv</span>, [<span class="number">128</span>, <span class="number">3</span>, <span class="number">2</span>]],</span><br><span class="line">   <span class="string">...</span>]</span><br><span class="line"></span><br><span class="line"><span class="attr">head:</span></span><br><span class="line">  [[<span class="number">-1</span>, <span class="number">1</span>, <span class="string">Detect</span>, [<span class="string">nc</span>, <span class="string">anchors</span>]]]</span><br></pre></td></tr></table></figure><blockquote><p>✅ 训练时，使用的是你自己选择的模型结构文件（通过 <code>--cfg</code> 或 <code>--weights</code> 推断出）。</p></blockquote><hr><h4 id="⚙️-3-hyp-yaml-—-超参数配置文件（学习率、增强、损失函数等超参数）"><a href="#⚙️-3-hyp-yaml-—-超参数配置文件（学习率、增强、损失函数等超参数）" class="headerlink" title="⚙️ 3. hyp.yaml — 超参数配置文件（学习率、增强、损失函数等超参数）"></a>⚙️ 3. <code>hyp.yaml</code> — 超参数配置文件（<strong>学习率、增强、损失函数等超参数</strong>）</h4><p>位置：默认在 <code>data/hyps/</code> 目录下，如 <code>hyp.scratch-low.yaml</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">lr0:</span> <span class="number">0.01</span>           <span class="comment"># 初始学习率</span></span><br><span class="line"><span class="attr">lrf:</span> <span class="number">0.01</span>           <span class="comment"># 最终学习率 (final LR = lr0 * lrf)</span></span><br><span class="line"><span class="attr">momentum:</span> <span class="number">0.937</span>     <span class="comment"># SGD动量</span></span><br><span class="line"><span class="attr">weight_decay:</span> <span class="number">0.0005</span></span><br><span class="line"><span class="attr">warmup_epochs:</span> <span class="number">3.0</span>  <span class="comment"># 预热轮数</span></span><br><span class="line"><span class="attr">hsv_h:</span> <span class="number">0.015</span>        <span class="comment"># 色调增强</span></span><br><span class="line"><span class="attr">hsv_s:</span> <span class="number">0.7</span>          <span class="comment"># 饱和度增强</span></span><br><span class="line"><span class="attr">fl_gamma:</span> <span class="number">0.0</span>       <span class="comment"># Focal Loss gamma</span></span><br></pre></td></tr></table></figure><blockquote><p>你可以通过 <code>--hyp</code> 参数指定这个文件，例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --hyp data/hyps/hyp.scratch-low.yaml</span><br></pre></td></tr></table></figure></blockquote><hr><h4 id="✅-小结：三大核心配置文件说明表"><a href="#✅-小结：三大核心配置文件说明表" class="headerlink" title="✅ 小结：三大核心配置文件说明表"></a>✅ 小结：三大核心配置文件说明表</h4><div class="table-container"><table><thead><tr><th>配置文件</th><th>作用</th><th>常见位置</th></tr></thead><tbody><tr><td><code>data.yaml</code></td><td>指定训练/验证/测试集和类别信息</td><td>你项目目录 / <code>data/</code></td></tr><tr><td><code>*.yaml</code></td><td>定义模型结构（yolov5s 等）</td><td><code>models/</code></td></tr><tr><td><code>hyp.yaml</code></td><td>设置训练超参数（增强、LR 等）</td><td><code>data/hyps/</code></td></tr></tbody></table></div><hr><h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><h3 id="执行指令说明"><a href="#执行指令说明" class="headerlink" title="执行指令说明"></a>执行指令说明</h3><p>一般训练运行命令行命令：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --img 640 --batch 16 --epochs 50 --data wheat.yaml --weights yolov5s.pt --name wheat_yolov5</span><br></pre></td></tr></table></figure></p><hr><h4 id="📂-模型与数据相关参数"><a href="#📂-模型与数据相关参数" class="headerlink" title="📂 模型与数据相关参数"></a>📂 模型与数据相关参数</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--weights</code></td><td><code>str</code></td><td><code>yolov5s.pt</code></td><td>初始权重路径，可为官方模型或自定义训练的 <code>.pt</code> 文件。</td></tr><tr><td><code>--cfg</code></td><td><code>str</code></td><td><code>&quot;&quot;</code></td><td>模型结构配置文件（如 <code>yolov5s.yaml</code>）。为空则从 <code>weights</code> 推断。</td></tr><tr><td><code>--data</code></td><td><code>str</code></td><td><code>data/coco128.yaml</code></td><td>数据集配置文件，包含 <code>train</code>, <code>val</code>, <code>nc</code>, <code>names</code> 等字段。</td></tr><tr><td><code>--hyp</code></td><td><code>str</code></td><td><code>data/hyps/hyp.scratch-low.yaml</code></td><td>超参数配置文件，包括学习率、IoU阈值、损失等。</td></tr></tbody></table></div><hr><h4 id="📈-训练控制参数"><a href="#📈-训练控制参数" class="headerlink" title="📈 训练控制参数"></a>📈 训练控制参数</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--epochs</code></td><td><code>int</code></td><td><code>100</code></td><td>训练总轮数。</td></tr><tr><td><code>--batch-size</code></td><td><code>int</code></td><td><code>16</code></td><td>批大小，所有GPU总和。<code>-1</code> 表示自动推断。</td></tr><tr><td><code>--imgsz</code> / <code>--img</code> / <code>--img-size</code></td><td><code>int</code></td><td><code>640</code></td><td>输入图像尺寸（会缩放为正方形）。</td></tr><tr><td><code>--rect</code></td><td><code>store_true</code></td><td><code>False</code></td><td>是否启用矩形训练（图像按长宽比例分组）。</td></tr><tr><td><code>--multi-scale</code></td><td><code>store_true</code></td><td><code>False</code></td><td>是否在训练中动态改变图像大小（±50%）。</td></tr><tr><td><code>--resume</code></td><td>可选参数</td><td><code>False</code></td><td>是否从最近的断点继续训练。</td></tr><tr><td><code>--freeze</code></td><td><code>List[int]</code></td><td><code>[0]</code></td><td>冻结网络层，示例：<code>--freeze 0 1 2</code> 表示冻结前3层。</td></tr><tr><td><code>--single-cls</code></td><td><code>store_true</code></td><td><code>False</code></td><td>是否将所有类别视为一个类别（适用于单类数据）。</td></tr></tbody></table></div><hr><h4 id="💾-模型保存与验证参数"><a href="#💾-模型保存与验证参数" class="headerlink" title="💾 模型保存与验证参数"></a>💾 模型保存与验证参数</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--nosave</code></td><td><code>store_true</code></td><td><code>False</code></td><td>是否只保存最后一个模型，不保存中间checkpoint。</td></tr><tr><td><code>--noval</code></td><td><code>store_true</code></td><td><code>False</code></td><td>是否仅在最后一个 epoch 验证模型性能。</td></tr><tr><td><code>--save-period</code></td><td><code>int</code></td><td><code>-1</code></td><td>每间隔 x 个 epoch 保存一次模型。小于1表示禁用。</td></tr></tbody></table></div><hr><h4 id="🧠-超参数进化（进阶功能）"><a href="#🧠-超参数进化（进阶功能）" class="headerlink" title="🧠 超参数进化（进阶功能）"></a>🧠 超参数进化（进阶功能）</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--evolve</code></td><td><code>int</code></td><td>可选，默认<code>300</code></td><td>使用遗传算法自动进化超参数，运行 <code>x</code> 代。</td></tr><tr><td><code>--evolve_population</code></td><td><code>str</code></td><td><code>data/hyps</code></td><td>进化时加载的初始种群超参数路径。</td></tr><tr><td><code>--resume_evolve</code></td><td><code>str</code></td><td><code>None</code></td><td>从先前进化的最后一代恢复。</td></tr></tbody></table></div><hr><h4 id="🧰-运行控制参数"><a href="#🧰-运行控制参数" class="headerlink" title="🧰 运行控制参数"></a>🧰 运行控制参数</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--device</code></td><td><code>str</code></td><td><code>&quot;&quot;</code></td><td>指定设备：如 <code>0</code>、<code>0,1</code> 或 <code>cpu</code>。</td></tr><tr><td><code>--optimizer</code></td><td><code>str</code></td><td><code>SGD</code></td><td>选择优化器：<code>SGD</code>, <code>Adam</code>, <code>AdamW</code>。</td></tr><tr><td><code>--sync-bn</code></td><td><code>store_true</code></td><td><code>False</code></td><td>启用同步BatchNorm（仅 DDP 模式有效）。</td></tr><tr><td><code>--quad</code></td><td><code>store_true</code></td><td><code>False</code></td><td>启用四元加载器优化（某些GPU加速）。</td></tr><tr><td><code>--cos-lr</code></td><td><code>store_true</code></td><td><code>False</code></td><td>使用余弦学习率调度器。</td></tr><tr><td><code>--label-smoothing</code></td><td><code>float</code></td><td><code>0.0</code></td><td>标签平滑因子（防止过拟合）。</td></tr><tr><td><code>--patience</code></td><td><code>int</code></td><td><code>100</code></td><td>EarlyStopping容忍的无改进epoch数。</td></tr><tr><td><code>--seed</code></td><td><code>int</code></td><td><code>0</code></td><td>设置随机种子，确保结果可复现。</td></tr><tr><td><code>--workers</code></td><td><code>int</code></td><td><code>8</code></td><td>每个进程的数据加载线程数。</td></tr><tr><td><code>--local_rank</code></td><td><code>int</code></td><td><code>-1</code></td><td>DDP 多GPU模式下自动设置，不要手动修改。</td></tr></tbody></table></div><hr><h4 id="📝-日志记录与结果保存"><a href="#📝-日志记录与结果保存" class="headerlink" title="📝 日志记录与结果保存"></a>📝 日志记录与结果保存</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--project</code></td><td><code>str</code></td><td><code>runs/train</code></td><td>保存训练结果的项目目录。</td></tr><tr><td><code>--name</code></td><td><code>str</code></td><td><code>exp</code></td><td>子目录名称。</td></tr><tr><td><code>--exist-ok</code></td><td><code>store_true</code></td><td><code>False</code></td><td>如果目录存在，则不自动增加编号。</td></tr></tbody></table></div><hr><h4 id="☁️-云与缓存相关"><a href="#☁️-云与缓存相关" class="headerlink" title="☁️ 云与缓存相关"></a>☁️ 云与缓存相关</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--bucket</code></td><td><code>str</code></td><td><code>&quot;&quot;</code></td><td>用于 Google Cloud Storage 的 gsutil bucket 路径。</td></tr><tr><td><code>--cache</code></td><td><code>str</code></td><td>可选</td><td><code>ram</code> 或 <code>disk</code>，缓存图像到内存或硬盘以加速训练。</td></tr><tr><td><code>--image-weights</code></td><td><code>store_true</code></td><td><code>False</code></td><td>图像采样根据权重进行（提升少数类样本）。</td></tr></tbody></table></div><hr><h4 id="🔗-W-amp-B-Artifact-日志参数（用于实验追踪）"><a href="#🔗-W-amp-B-Artifact-日志参数（用于实验追踪）" class="headerlink" title="🔗 W\&amp;B / Artifact 日志参数（用于实验追踪）"></a>🔗 W\&amp;B / Artifact 日志参数（用于实验追踪）</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--entity</code></td><td><code>str</code></td><td><code>None</code></td><td>W\&amp;B 实验的团队或个人实体名。</td></tr><tr><td><code>--upload_dataset</code></td><td><code>store_true</code></td><td><code>False</code></td><td>是否上传数据集到 W\&amp;B。可选 <code>&quot;val&quot;</code>。</td></tr><tr><td><code>--bbox_interval</code></td><td><code>int</code></td><td><code>-1</code></td><td>日志中显示检测框图片的间隔 epoch。</td></tr><tr><td><code>--artifact_alias</code></td><td><code>str</code></td><td><code>&quot;latest&quot;</code></td><td>指定使用的 artifact 版本标签。</td></tr></tbody></table></div><hr><h4 id="🧾-NDJSON-日志参数（结构化日志）"><a href="#🧾-NDJSON-日志参数（结构化日志）" class="headerlink" title="🧾 NDJSON 日志参数（结构化日志）"></a>🧾 NDJSON 日志参数（结构化日志）</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--ndjson-console</code></td><td><code>store_true</code></td><td><code>False</code></td><td>在控制台输出 ndjson 格式日志。</td></tr><tr><td><code>--ndjson-file</code></td><td><code>store_true</code></td><td><code>False</code></td><td>将 ndjson 日志输出到文件。</td></tr></tbody></table></div><hr><h2 id="模型推理与验证"><a href="#模型推理与验证" class="headerlink" title="模型推理与验证"></a>模型推理与验证</h2><h3 id="执行指令说明-1"><a href="#执行指令说明-1" class="headerlink" title="执行指令说明"></a>执行指令说明</h3><p>一般目标检测执行命令：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python detect.py --weights runs/train/wheat_yolov5/weights/best.pt --source /test_image_folder --img 640 --conf 0.25 --save-txt --save-conf --project runs/predict --name wheat_test</span><br></pre></td></tr></table></figure></p><h4 id="🎯-核心推理参数"><a href="#🎯-核心推理参数" class="headerlink" title="🎯 核心推理参数"></a>🎯 核心推理参数</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--weights</code></td><td><code>str/list[str]</code></td><td><code>yolov5s.pt</code></td><td>模型路径（<code>.pt</code> 文件），也可为多个模型或 Triton 服务器地址。</td></tr><tr><td><code>--source</code></td><td><code>str</code></td><td><code>data/images</code></td><td>输入来源：文件、文件夹、URL、glob、摄像头（如 <code>0</code>）或 <code>screen</code>。</td></tr><tr><td><code>--data</code></td><td><code>str</code></td><td><code>data/coco128.yaml</code></td><td>数据集配置文件（可选）。用于加载类别名等信息。</td></tr><tr><td><code>--imgsz</code> / <code>--img</code> / <code>--img-size</code></td><td><code>list[int]</code></td><td><code>[640]</code></td><td>推理图像的尺寸，单个值或 <code>[h, w]</code>。如果只给一个，则会扩展成 <code>[640, 640]</code>。</td></tr><tr><td><code>--conf-thres</code></td><td><code>float</code></td><td><code>0.25</code></td><td>置信度阈值，低于该值的检测框会被过滤。</td></tr><tr><td><code>--iou-thres</code></td><td><code>float</code></td><td><code>0.45</code></td><td>非极大值抑制（NMS）中的 IoU 阈值。</td></tr><tr><td><code>--max-det</code></td><td><code>int</code></td><td><code>1000</code></td><td>每张图片最多保留的目标检测数量。</td></tr><tr><td><code>--device</code></td><td><code>str</code></td><td><code>&quot;&quot;</code></td><td>计算设备，如 <code>&#39;0&#39;</code>, <code>&#39;0,1&#39;</code>, <code>&#39;cpu&#39;</code> 等。</td></tr></tbody></table></div><hr><h4 id="🖼️-可视化与保存选项"><a href="#🖼️-可视化与保存选项" class="headerlink" title="🖼️ 可视化与保存选项"></a>🖼️ 可视化与保存选项</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--view-img</code></td><td><code>bool</code></td><td><code>False</code></td><td>是否显示检测结果图像（本地窗口）。</td></tr><tr><td><code>--save-txt</code></td><td><code>bool</code></td><td><code>False</code></td><td>是否将检测结果保存为 <code>.txt</code> 文件（YOLO格式或Pascal VOC格式）。</td></tr><tr><td><code>--save-format</code></td><td><code>int</code></td><td><code>0</code></td><td>配合 <code>--save-txt</code>：<code>0</code> 为 YOLO 格式，<code>1</code> 为 Pascal VOC 格式。</td></tr><tr><td><code>--save-csv</code></td><td><code>bool</code></td><td><code>False</code></td><td>是否将结果保存为 <code>.csv</code> 文件。</td></tr><tr><td><code>--save-conf</code></td><td><code>bool</code></td><td><code>False</code></td><td>是否将置信度一同保存到 <code>.txt</code> 文件中。</td></tr><tr><td><code>--save-crop</code></td><td><code>bool</code></td><td><code>False</code></td><td>是否保存每个检测框裁剪出的目标图像。</td></tr><tr><td><code>--nosave</code></td><td><code>bool</code></td><td><code>False</code></td><td>不保存任何图像或视频结果，仅在控制台输出。</td></tr><tr><td><code>--project</code></td><td><code>str</code></td><td><code>runs/detect</code></td><td>结果保存根目录。</td></tr><tr><td><code>--name</code></td><td><code>str</code></td><td><code>exp</code></td><td>子目录名称。</td></tr><tr><td><code>--exist-ok</code></td><td><code>bool</code></td><td><code>False</code></td><td>如果目录已存在，不自动创建 <code>exp2</code>, <code>exp3</code>，而是直接覆盖或重用。</td></tr><tr><td><code>--line-thickness</code></td><td><code>int</code></td><td><code>3</code></td><td>检测框的线宽（像素）。</td></tr><tr><td><code>--hide-labels</code></td><td><code>bool</code></td><td><code>False</code></td><td>不在图像上显示类别标签。</td></tr><tr><td><code>--hide-conf</code></td><td><code>bool</code></td><td><code>False</code></td><td>不在图像上显示置信度分数。</td></tr></tbody></table></div><hr><h4 id="📊-检测控制选项"><a href="#📊-检测控制选项" class="headerlink" title="📊 检测控制选项"></a>📊 检测控制选项</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--classes</code></td><td><code>list[int]</code></td><td><code>None</code></td><td>仅检测指定类别，例如 <code>--classes 0 2 3</code>。</td></tr><tr><td><code>--agnostic-nms</code></td><td><code>bool</code></td><td><code>False</code></td><td>使用类别无关的 NMS（所有类别共用抑制逻辑）。</td></tr><tr><td><code>--augment</code></td><td><code>bool</code></td><td><code>False</code></td><td>启用数据增强的推理（略慢但可能更鲁棒）。</td></tr><tr><td><code>--visualize</code></td><td><code>bool</code></td><td><code>False</code></td><td>可视化中间特征图（需模型支持）。</td></tr><tr><td><code>--update</code></td><td><code>bool</code></td><td><code>False</code></td><td>自动更新模型（转换旧格式为新格式）。</td></tr><tr><td><code>--half</code></td><td><code>bool</code></td><td><code>False</code></td><td>使用半精度（FP16）推理，仅限于 <code>CUDA</code>。</td></tr><tr><td><code>--dnn</code></td><td><code>bool</code></td><td><code>False</code></td><td>使用 OpenCV DNN 模式进行 ONNX 推理。</td></tr><tr><td><code>--vid-stride</code></td><td><code>int</code></td><td><code>1</code></td><td>视频推理时的帧跳跃间隔，例如 <code>--vid-stride 5</code> 表示每5帧处理一帧。</td></tr></tbody></table></div><hr><h4 id="✅-示例命令"><a href="#✅-示例命令" class="headerlink" title="✅ 示例命令"></a>✅ 示例命令</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检测单张图片并保存结果</span></span><br><span class="line">python detect.py --weights yolov5s.pt --<span class="built_in">source</span> ./data/images/zidane.jpg --conf-thres 0.3 --save-txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 仅检测类别 0 和 2，显示结果但不保存图像</span></span><br><span class="line">python detect.py --weights yolov5s.pt --<span class="built_in">source</span> ./data/images --classes 0 2 --view-img --nosave</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对视频推理，每5帧检测一次，保存检测框为 Pascal VOC 格式</span></span><br><span class="line">python detect.py --weights yolov5s.pt --<span class="built_in">source</span> video.mp4 --vid-stride 5 --save-txt --save-format 1</span><br></pre></td></tr></table></figure><h2 id="模型导出与部署"><a href="#模型导出与部署" class="headerlink" title="模型导出与部署"></a>模型导出与部署</h2><h3 id="执行指令说明-2"><a href="#执行指令说明-2" class="headerlink" title="执行指令说明"></a>执行指令说明</h3><p>以下是对每个命令行参数的详细解释：</p><hr><h4 id="🗂️-数据和模型路径配置"><a href="#🗂️-数据和模型路径配置" class="headerlink" title="🗂️ 数据和模型路径配置"></a>🗂️ 数据和模型路径配置</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--data</code></td><td>str</td><td><code>data/coco128.yaml</code></td><td>数据集配置文件路径，主要用于获取类别数等信息</td></tr><tr><td><code>--weights</code></td><td>str/list</td><td><code>yolov5s.pt</code></td><td>训练好的模型权重路径，支持多个模型同时导出</td></tr><tr><td><code>--imgsz</code> / <code>--img</code> / <code>--img-size</code></td><td>int list</td><td><code>[640, 640]</code></td><td>输入图片尺寸 <code>[height, width]</code>，默认是正方形</td></tr><tr><td><code>--batch-size</code></td><td>int</td><td>1</td><td>推理时的 batch size，一般保持为1以防不兼容</td></tr></tbody></table></div><hr><h4 id="⚙️-设备和推理精度"><a href="#⚙️-设备和推理精度" class="headerlink" title="⚙️ 设备和推理精度"></a>⚙️ 设备和推理精度</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--device</code></td><td>str</td><td><code>cpu</code></td><td>运行导出过程所使用的设备，如 <code>0</code>, <code>cpu</code>, <code>0,1</code> 等</td></tr><tr><td><code>--half</code></td><td>flag</td><td>False</td><td>是否使用 FP16 精度导出（仅限支持的平台）</td></tr></tbody></table></div><hr><h4 id="⚙️-导出行为控制"><a href="#⚙️-导出行为控制" class="headerlink" title="⚙️ 导出行为控制"></a>⚙️ 导出行为控制</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--inplace</code></td><td>flag</td><td>False</td><td>是否将 Detect() 的 <code>inplace=True</code>，影响模型输出张量的修改方式</td></tr><tr><td><code>--keras</code></td><td>flag</td><td>False</td><td>TensorFlow 导出时是否使用 Keras 模式（<code>.h5</code>）</td></tr><tr><td><code>--optimize</code></td><td>flag</td><td>False</td><td>TorchScript 优化用于移动端部署（会应用 graph 优化）</td></tr></tbody></table></div><hr><h4 id="🎯-量化和动态轴控制"><a href="#🎯-量化和动态轴控制" class="headerlink" title="🎯 量化和动态轴控制"></a>🎯 量化和动态轴控制</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--int8</code></td><td>flag</td><td>False</td><td>导出 INT8 量化模型（支持 TF、CoreML、OpenVINO）</td></tr><tr><td><code>--per-tensor</code></td><td>flag</td><td>False</td><td>TensorFlow 的 per-tensor 量化方式（默认是 per-channel）</td></tr><tr><td><code>--dynamic</code></td><td>flag</td><td>False</td><td>启用动态输入尺寸（支持 ONNX、TF、TensorRT）</td></tr></tbody></table></div><hr><h4 id="🧠-ONNX-相关"><a href="#🧠-ONNX-相关" class="headerlink" title="🧠 ONNX 相关"></a>🧠 ONNX 相关</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--simplify</code></td><td>flag</td><td>False</td><td>简化 ONNX 模型图（需安装 <code>onnxsim</code>）</td></tr><tr><td><code>--opset</code></td><td>int</td><td>17</td><td>ONNX 的 opset 版本，常见为 11~17</td></tr></tbody></table></div><hr><h4 id="🧠-TensorRT-相关"><a href="#🧠-TensorRT-相关" class="headerlink" title="🧠 TensorRT 相关"></a>🧠 TensorRT 相关</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--engine</code>（由 <code>--include engine</code> 控制）</td><td></td><td></td><td>TensorRT 导出开关</td></tr><tr><td><code>--cache</code></td><td>str</td><td>“”</td><td>TensorRT 的时间 cache 文件路径（加速编译）</td></tr><tr><td><code>--workspace</code></td><td>int</td><td>4</td><td>TensorRT 最大 workspace 大小（单位 GB）</td></tr><tr><td><code>--verbose</code></td><td>flag</td><td>False</td><td>TensorRT 导出时是否打印详细日志</td></tr></tbody></table></div><hr><h4 id="🍏-CoreML-相关"><a href="#🍏-CoreML-相关" class="headerlink" title="🍏 CoreML 相关"></a>🍏 CoreML 相关</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--mlmodel</code></td><td>flag</td><td>False</td><td>导出 CoreML <code>.mlmodel</code> 格式</td></tr><tr><td><code>--int8</code></td><td>flag</td><td>False</td><td>可配合用于量化 CoreML</td></tr></tbody></table></div><hr><h4 id="🧪-TensorFlow-js（TF-js）相关（用于-Web-端）"><a href="#🧪-TensorFlow-js（TF-js）相关（用于-Web-端）" class="headerlink" title="🧪 TensorFlow.js（TF.js）相关（用于 Web 端）"></a>🧪 TensorFlow.js（TF.js）相关（用于 Web 端）</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--nms</code></td><td>flag</td><td>False</td><td>添加非极大抑制 NMS（默认模型中不包含）</td></tr><tr><td><code>--agnostic-nms</code></td><td>flag</td><td>False</td><td>类别无关的 NMS</td></tr><tr><td><code>--topk-per-class</code></td><td>int</td><td>100</td><td>每个类别保留前 K 个检测结果</td></tr><tr><td><code>--topk-all</code></td><td>int</td><td>100</td><td>所有类别一共保留前 K 个检测结果</td></tr><tr><td><code>--iou-thres</code></td><td>float</td><td>0.45</td><td>NMS 的 IoU 阈值</td></tr><tr><td><code>--conf-thres</code></td><td>float</td><td>0.25</td><td>置信度阈值，低于此值的框会被丢弃</td></tr></tbody></table></div><hr><h4 id="🎯-导出格式设置（核心参数）"><a href="#🎯-导出格式设置（核心参数）" class="headerlink" title="🎯 导出格式设置（核心参数）"></a>🎯 导出格式设置（核心参数）</h4><div class="table-container"><table><thead><tr><th>参数</th><th>类型</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td><code>--include</code></td><td>list</td><td><code>[&#39;torchscript&#39;]</code></td><td>要导出的格式，可以包含多个：<br> <code>torchscript</code>, <code>onnx</code>, <code>openvino</code>, <code>engine</code>, <code>coreml</code>, <code>saved_model</code>, <code>pb</code>, <code>tflite</code>, <code>edgetpu</code>, <code>tfjs</code>, <code>paddle</code> 等</td></tr></tbody></table></div><hr><h3 id="✅-示例用法"><a href="#✅-示例用法" class="headerlink" title="✅ 示例用法"></a>✅ 示例用法</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导出 ONNX + TorchScript + TensorRT 引擎（使用 GPU）</span></span><br><span class="line">python export.py \</span><br><span class="line">  --weights yolov5s.pt \</span><br><span class="line">  --img 640 \</span><br><span class="line">  --device 0 \</span><br><span class="line">  --include onnx torchscript engine \</span><br><span class="line">  --dynamic \</span><br><span class="line">  --simplify \</span><br><span class="line">  --opset 17</span><br></pre></td></tr></table></figure><hr><p>PS：封面图来源：<a href="https://x.com/nakiriayame/status/1946478772301213900?s=46"><br>百鬼あやめ😈ホロライブ2期生</a></p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;YOLOv5使用方法&quot;&gt;&lt;a href=&quot;#YOLOv5使用方法&quot; class=&quot;headerlink&quot; title=&quot;YOLOv5使用方法&quot;&gt;&lt;/a&gt;YOLOv5使用方法&lt;/h1&gt;&lt;h2 id=&quot;数据集&quot;&gt;&lt;a href=&quot;#数据集&quot;</summary>
        
      
    
    
    
    <category term="深度学习" scheme="https://blog.whff521.xyz/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="yolo" scheme="https://blog.whff521.xyz/tags/yolo/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle:  CIFAR-10-Object Recognition in Images</title>
    <link href="https://blog.whff521.xyz/2025/07/19/Kaggle-CIFAR-10-Object-Recognition-in-Images/"/>
    <id>https://blog.whff521.xyz/2025/07/19/Kaggle-CIFAR-10-Object-Recognition-in-Images/</id>
    <published>2025-07-19T02:14:45.000Z</published>
    <updated>2025-07-19T06:42:29.826Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Kaggle-CIFAR-10-Object-Recognition-in-Images"><a href="#Kaggle-CIFAR-10-Object-Recognition-in-Images" class="headerlink" title="Kaggle:  CIFAR-10-Object Recognition in Images"></a>Kaggle:  CIFAR-10-Object Recognition in Images</h1><p>本文是实现<code>d2l</code>网站代码的总结，<a href="https://zh.d2l.ai/chapter_computer-vision/kaggle-cifar10.html#fig-kaggle-cifar10">教程链接</a></p><p>本文所用环境如下：<br><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python==3.9.23</span><br><span class="line">nvidia-cuda-runtime-cu12==12.9.79</span><br><span class="line">torch==2.7.1+cu118</span><br><span class="line">d2l==1.0.3</span><br></pre></td></tr></table></figure></p><h2 id="📚-数据集介绍"><a href="#📚-数据集介绍" class="headerlink" title="📚 数据集介绍"></a>📚 数据集介绍</h2><p>CIFAR-10 是由加拿大多伦多大学 Alex Krizhevsky 等人收集的图像数据集，包含了 <strong>10 个类别的彩色图片</strong>。这些图片都是从真实世界拍摄的物体中裁剪而来的。</p><h3 id="📏-数据细节："><a href="#📏-数据细节：" class="headerlink" title="📏 数据细节："></a>📏 数据细节：</h3><div class="table-container"><table><thead><tr><th>项目</th><th>描述</th></tr></thead><tbody><tr><td>图片大小</td><td>32x32 像素，RGB（三通道）</td></tr><tr><td>图片数量</td><td>60,000 张图像</td></tr><tr><td>类别数量</td><td>10 个</td></tr><tr><td>训练集</td><td>50,000 张图像</td></tr><tr><td>测试集</td><td>10,000 张图像</td></tr><tr><td>图像格式</td><td><code>.png</code> 图像 + <code>.csv</code> 标签/预测</td></tr></tbody></table></div><h2 id="预测流程"><a href="#预测流程" class="headerlink" title="预测流程"></a>预测流程</h2><h3 id="导包"><a href="#导包" class="headerlink" title="导包"></a>导包</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br></pre></td></tr></table></figure><h3 id="数据整理"><a href="#数据整理" class="headerlink" title="数据整理"></a>数据整理</h3><p>我是将完整的数据集下载到本地然后直接用全部数据进行训练的。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置数据集的存储位置</span></span><br><span class="line">data_dir = <span class="string">&#x27;D:\datasets\cifar-10&#x27;</span> </span><br></pre></td></tr></table></figure><p>文件夹中有<code>trainLabels.csv</code>,里边有<code>id</code>和<code>label</code>两列，分别代表图片名称和标签。</p><p>原教程是直接读取的文件，根据csv文件是用逗号分隔将文件拆成两部分然后转换成字典类型，实际上直接用<code>pandas</code>库就可以直接读取：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">read_csv_labels</span>(<span class="params">fname</span>):</span><br><span class="line">    df = pd.read_csv(fname)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">dict</span>(<span class="built_in">zip</span>(df[<span class="string">&#x27;id&#x27;</span>], df[<span class="string">&#x27;label&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">labels = read_csv_labels(os.path.join(data_dir,<span class="string">&#x27;trainLabels.csv&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;# training examples:&#x27;</span>, <span class="built_in">len</span>(labels))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;# classes:&#x27;</span>, <span class="built_in">len</span>(<span class="built_in">set</span>(labels.values())))</span><br></pre></td></tr></table></figure><p>这样我们就得到了标签字典，可以直接用<code>labels</code>查看图片的标签。</p><p>教程中为了方便读取图片，将图片的存储位置重新整理了一下，建立<code>train_valid_test</code>文件夹，里面有<code>train</code>,<code>valid</code>,<code>test</code>和<code>train_valid</code>四个文件夹。除了<code>test</code>文件夹，其他文件夹内均按照标签分成10个文件夹，每个图片根据自己的标签放到相应的文件夹里，这样做是为了后面分组的时候每组的标签尽量均匀。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">copyfile</span>(<span class="params">filename, target_dir</span>):</span><br><span class="line">    os.makedirs(target_dir,exist_ok=<span class="literal">True</span>)</span><br><span class="line">    shutil.copy(filename,target_dir)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">reorg_train_valid</span>(<span class="params">data_dir, labels, valid_ratio</span>):</span><br><span class="line">    <span class="comment"># The number of examples of the class that has the fewest examples in the</span></span><br><span class="line">    <span class="comment"># training dataset</span></span><br><span class="line">    n = collections.Counter(labels.values()).most_common()[-<span class="number">1</span>][<span class="number">1</span>]</span><br><span class="line">    n_valid_per_label = <span class="built_in">max</span>(<span class="number">1</span>,math.floor(n * valid_ratio))</span><br><span class="line">    label_count=&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> train_file <span class="keyword">in</span> os.listdir(os.path.join(data_dir,<span class="string">&#x27;train&#x27;</span>)):</span><br><span class="line">        label = labels[train_file.split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>]]</span><br><span class="line">        fname = os.path.join(data_dir,<span class="string">&#x27;train&#x27;</span>,train_file)</span><br><span class="line">        copyfile(fname,os.path.join(data_dir,<span class="string">&#x27;train_valid_test&#x27;</span>,<span class="string">&#x27;train_valid&#x27;</span>,label))</span><br><span class="line">        <span class="keyword">if</span> label <span class="keyword">not</span> <span class="keyword">in</span> label_count <span class="keyword">or</span> label_count[label] &lt;n_valid_per_label:</span><br><span class="line">            copyfile(fname, os.path.join(data_dir,<span class="string">&#x27;train_valid_test&#x27;</span>,<span class="string">&#x27;valid&#x27;</span>,label))</span><br><span class="line">            label_count[label] = label_count.get(label,<span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line">            copyfile(fname, os.path.join(data_dir, <span class="string">&#x27;train_valid_test&#x27;</span>,<span class="string">&#x27;train&#x27;</span>,label))</span><br><span class="line">    <span class="keyword">return</span> n_valid_per_label</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">reorg_test</span>(<span class="params">data_dir</span>):</span><br><span class="line">    <span class="keyword">for</span> test_file <span class="keyword">in</span> os.listdir(os.path.join(data_dir,<span class="string">&#x27;test&#x27;</span>)):</span><br><span class="line">        copyfile(os.path.join(data_dir, <span class="string">&#x27;test&#x27;</span>, test_file),</span><br><span class="line">                 os.path.join(data_dir,<span class="string">&#x27;train_valid_test&#x27;</span>,<span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;unknown&#x27;</span>))</span><br></pre></td></tr></table></figure><p><code>valid_ratio</code>：验证集占比，如0.1表示验证集500张，训练集4500张</p><p>然后定义一个整合函数，将上面的函数流程统一处理：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">reorg_cifar10_data</span>(<span class="params">data_dir,valid_ratio</span>):</span><br><span class="line">    labels = read_csv_labels(os.path.join(data_dir, <span class="string">&#x27;trainLabels.csv&#x27;</span>))</span><br><span class="line">    reorg_train_valid(data_dir, labels, valid_ratio)</span><br><span class="line">    reorg_test(data_dir)</span><br></pre></td></tr></table></figure></p><p>设置批量大小为128，将10％的训练样本作为调整超参数的验证集</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">valid_ratio = <span class="number">0.1</span></span><br><span class="line">reorg_cifar10_data(data_dir,valid_ratio)</span><br></pre></td></tr></table></figure><h3 id="图像增广"><a href="#图像增广" class="headerlink" title="图像增广"></a>图像增广</h3><p>为了防止过拟合，一般会采用图像增广。</p><p>标准化的原因：</p><ol><li>加快模型收敛速度。让特征值范围大致分布在[-1,1]</li><li>避免某些特征主导模型训练。让各通道均值为0，方差为1，平衡每个像素的“权重”</li><li>提高模型泛化能力</li></ol><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">transform_train = torchvision.transforms.Compose([</span><br><span class="line">    <span class="comment"># 在高度和宽度上将图像放大到40像素的正方形</span></span><br><span class="line">    torchvision.transforms.Resize(<span class="number">40</span>),</span><br><span class="line">    <span class="comment"># 随机裁剪出一个高度和宽度均为40像素的正方形图像，</span></span><br><span class="line">    <span class="comment"># 生成一个面积为原始图像面积0.64～1倍的小正方形，</span></span><br><span class="line">    <span class="comment"># 然后将其缩放为高度和宽度均为32像素的正方形</span></span><br><span class="line">    torchvision.transforms.RandomResizedCrop(<span class="number">32</span>, scale=(<span class="number">0.64</span>, <span class="number">1.0</span>),</span><br><span class="line">                                                   ratio=(<span class="number">1.0</span>, <span class="number">1.0</span>)),</span><br><span class="line">    <span class="comment"># 随机水平翻转</span></span><br><span class="line">    torchvision.transforms.RandomHorizontalFlip(),</span><br><span class="line">    torchvision.transforms.ToTensor(),</span><br><span class="line">    <span class="comment"># 标准化图像的每个通道</span></span><br><span class="line">    <span class="comment"># 数字是根据数据集提前计算的，前面是RGB均值，后边是标准差</span></span><br><span class="line">    torchvision.transforms.Normalize([<span class="number">0.4914</span>, <span class="number">0.4822</span>, <span class="number">0.4465</span>],</span><br><span class="line">                                     [<span class="number">0.2023</span>, <span class="number">0.1994</span>, <span class="number">0.2010</span>])])</span><br><span class="line"><span class="comment"># 测试只执行标准化</span></span><br><span class="line">transform_test = torchvision.transforms.Compose([</span><br><span class="line">    torchvision.transforms.ToTensor(),</span><br><span class="line">    torchvision.transforms.Normalize([<span class="number">0.4914</span>, <span class="number">0.4822</span>, <span class="number">0.4465</span>],</span><br><span class="line">                                     [<span class="number">0.2023</span>, <span class="number">0.1994</span>, <span class="number">0.2010</span>])])</span><br></pre></td></tr></table></figure><h3 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h3><p>四个dataset列表：训练集，训练验证集，验证集，测试集</p><p>使用训练集和验证集组合而成的数据集（训练验证集）进行训练，充分利用所有标记的数据。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用列表推导式简洁地加载两个不同子目录的图像数据集，并应用同样的图像增强 transform_train</span></span><br><span class="line">train_ds, train_valid_ds = [torchvision.datasets.ImageFolder(</span><br><span class="line">    os.path.join(data_dir,<span class="string">&#x27;train_valid_test&#x27;</span>,folder),</span><br><span class="line">    transform=transform_train</span><br><span class="line">) <span class="keyword">for</span> folder <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>,<span class="string">&#x27;train_valid&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">valid_ds, test_ds = [torchvision.datasets.ImageFolder(</span><br><span class="line">    os.path.join(data_dir,<span class="string">&#x27;train_valid_test&#x27;</span>,folder),</span><br><span class="line">    transform=transform_test</span><br><span class="line">) <span class="keyword">for</span> folder <span class="keyword">in</span> [<span class="string">&#x27;valid&#x27;</span>,<span class="string">&#x27;test&#x27;</span>]]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;train_ds size:&quot;</span>, <span class="built_in">len</span>(train_ds))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;train_valid_ds size:&quot;</span>, <span class="built_in">len</span>(train_valid_ds))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;valid_ds size:&quot;</span>, <span class="built_in">len</span>(valid_ds))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test_ds size:&quot;</span>, <span class="built_in">len</span>(test_ds))</span><br></pre></td></tr></table></figure><p>还需要将上面的数据集转换为可迭代的对象：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用 DataLoader 创建了训练、验证、测试用的数据迭代器，分别控制是否打乱顺序、是否丢弃最后不足一批的数据</span></span><br><span class="line">train_iter, train_valid_iter = [torch.utils.data.DataLoader(</span><br><span class="line">    dataset, batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span></span><br><span class="line">) <span class="keyword">for</span> dataset <span class="keyword">in</span> (train_ds, train_valid_ds)]</span><br><span class="line"></span><br><span class="line">valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size,shuffle=<span class="literal">False</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=<span class="literal">False</span>,drop_last=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h3 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h3><p>使用<code>Resnet-18</code>模型</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_net</span>():</span><br><span class="line">    <span class="comment"># 数据集一共有10个类别</span></span><br><span class="line">    num_classes = <span class="number">10</span></span><br><span class="line">    <span class="comment"># 3 指RGB 3个通道数</span></span><br><span class="line">    net = d2l.resnet18(num_classes, <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> net</span><br><span class="line"><span class="comment"># 交叉熵损失函数，none表示不自动求平均或求和，返回的是每个样本的loss</span></span><br><span class="line">loss = nn.CrossEntropyLoss(reduction=<span class="string">&quot;none&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="定义训练函数"><a href="#定义训练函数" class="headerlink" title="定义训练函数"></a>定义训练函数</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">net,</span></span><br><span class="line"><span class="params">          train_iter,</span></span><br><span class="line"><span class="params">          valid_iter,</span></span><br><span class="line"><span class="params">          num_epochs,</span></span><br><span class="line"><span class="params">          lr,</span></span><br><span class="line"><span class="params">          wd,</span></span><br><span class="line"><span class="params">          devices,</span></span><br><span class="line"><span class="params">          lr_period,</span></span><br><span class="line"><span class="params">          lr_decay</span>):</span><br><span class="line">    <span class="comment"># 定义优化器：使用带动量的SGD优化器，包含学习率和权重衰减</span></span><br><span class="line">    trainer = torch.optim.SGD(net.parameters(), lr=lr, momentum=<span class="number">0.9</span>, weight_decay=wd)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 学习率调度器：每隔 lr_period 个 epoch，将学习率乘以 lr_decay</span></span><br><span class="line">    scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_period, lr_decay)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取训练集的批次数量，初始化计时器</span></span><br><span class="line">    num_batches, timer = <span class="built_in">len</span>(train_iter), d2l.Timer()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置绘图图例</span></span><br><span class="line">    legend = [<span class="string">&#x27;train loss&#x27;</span>, <span class="string">&#x27;train acc&#x27;</span>]</span><br><span class="line">    <span class="keyword">if</span> valid_iter <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        legend.append(<span class="string">&#x27;valid acc&#x27;</span>)  <span class="comment"># 如果有验证集，则加上验证准确率</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 动画器：用于可视化训练过程（损失和准确率）</span></span><br><span class="line">    animator = d2l.Animator(xlabel=<span class="string">&#x27;epoch&#x27;</span>, xlim=[<span class="number">1</span>, num_epochs], legend=legend)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用多GPU训练，将模型包装为 DataParallel 并移动到指定设备上</span></span><br><span class="line">    net = nn.DataParallel(net, device_ids=devices).to(devices[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        net.train()  <span class="comment"># 设置模型为训练模式</span></span><br><span class="line">        metric = d2l.Accumulator(<span class="number">3</span>)  <span class="comment"># 累加器：记录训练损失、训练准确率、样本数量</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, (features, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_iter):</span><br><span class="line">            timer.start()  <span class="comment"># 开始计时</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 单个 batch 的训练，返回损失和准确率</span></span><br><span class="line">            l, acc = d2l.train_batch_ch13(net, features, labels, loss, trainer, devices)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 累加损失、准确率、样本数</span></span><br><span class="line">            metric.add(l, acc, labels.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">            timer.stop()  <span class="comment"># 停止计时</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 每训练 1/5 的 batch 或最后一个 batch 时更新图像</span></span><br><span class="line">            <span class="keyword">if</span> (i + <span class="number">1</span>) % (num_batches // <span class="number">5</span>) == <span class="number">0</span> <span class="keyword">or</span> i == num_batches - <span class="number">1</span>:</span><br><span class="line">                animator.add(epoch + (i+<span class="number">1</span>) / num_batches,</span><br><span class="line">                             (metric[<span class="number">0</span>] / metric[<span class="number">2</span>],  <span class="comment"># 平均训练损失</span></span><br><span class="line">                              metric[<span class="number">1</span>] / metric[<span class="number">2</span>],  <span class="comment"># 平均训练准确率</span></span><br><span class="line">                              <span class="literal">None</span>))  <span class="comment"># 暂时不更新验证准确率</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果有验证集，在每个 epoch 结束后评估验证准确率并可视化</span></span><br><span class="line">        <span class="keyword">if</span> valid_iter <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            valid_acc = d2l.evaluate_accuracy_gpu(net, valid_iter)</span><br><span class="line">            animator.add(epoch + <span class="number">1</span>, (<span class="literal">None</span>, <span class="literal">None</span>, valid_acc))  <span class="comment"># 只更新验证准确率</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新学习率（根据学习率调度器）</span></span><br><span class="line">        scheduler.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印最终的训练指标</span></span><br><span class="line">    measures = (<span class="string">f&#x27;train loss <span class="subst">&#123;metric[<span class="number">0</span>] / metric[<span class="number">2</span>]:<span class="number">.3</span>f&#125;</span>, &#x27;</span></span><br><span class="line">                <span class="string">f&#x27;train acc <span class="subst">&#123;metric[<span class="number">1</span>] / metric[<span class="number">2</span>]:<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> valid_iter <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        measures += <span class="string">f&#x27;, valid acc <span class="subst">&#123;valid_acc:<span class="number">.3</span>f&#125;</span>&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印训练速度和设备信息</span></span><br><span class="line">    <span class="built_in">print</span>(measures + <span class="string">f&#x27;\n<span class="subst">&#123;metric[<span class="number">2</span>] * num_epochs / timer.<span class="built_in">sum</span>():<span class="number">.1</span>f&#125;</span>&#x27;</span></span><br><span class="line">          <span class="string">f&#x27; examples/sec on <span class="subst">&#123;<span class="built_in">str</span>(devices)&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="训练和验证模型"><a href="#训练和验证模型" class="headerlink" title="训练和验证模型"></a>训练和验证模型</h3><p>定义超参数和训练模型</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">devices, num_epochs, lr, wd = d2l.try_all_gpus(), <span class="number">20</span>, <span class="number">2e-4</span>, <span class="number">5e-4</span></span><br><span class="line">lr_period, lr_decay, net = <span class="number">4</span>, <span class="number">0.9</span>, get_net()</span><br><span class="line">train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,</span><br><span class="line">      lr_decay)</span><br></pre></td></tr></table></figure><h3 id="对测试集进行分类并生成结果"><a href="#对测试集进行分类并生成结果" class="headerlink" title="对测试集进行分类并生成结果"></a>对测试集进行分类并生成结果</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">net, preds = get_net(), []</span><br><span class="line">train(net, train_valid_iter, <span class="literal">None</span>, num_epochs, lr, wd, devices, lr_period,</span><br><span class="line">      lr_decay)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> X, _ <span class="keyword">in</span> test_iter:</span><br><span class="line">    y_hat = net(X.to(devices[<span class="number">0</span>]))</span><br><span class="line">    preds.extend(y_hat.argmax(dim=<span class="number">1</span>).<span class="built_in">type</span>(torch.int32).cpu().numpy())</span><br><span class="line">sorted_ids = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(test_ds) + <span class="number">1</span>))</span><br><span class="line">sorted_ids.sort(key=<span class="keyword">lambda</span> x: <span class="built_in">str</span>(x))</span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;id&#x27;</span>: sorted_ids, <span class="string">&#x27;label&#x27;</span>: preds&#125;)</span><br><span class="line">df[<span class="string">&#x27;label&#x27;</span>] = df[<span class="string">&#x27;label&#x27;</span>].apply(<span class="keyword">lambda</span> x: train_valid_ds.classes[x])</span><br><span class="line">df.to_csv(<span class="string">&#x27;submission.csv&#x27;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>生成的<code>submission.csv</code>就可以提交到Kaggle上了。</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;Kaggle-CIFAR-10-Object-Recognition-in-Images&quot;&gt;&lt;a href=&quot;#Kaggle-CIFAR-10-Object-Recognition-in-Images&quot; class=&quot;headerlink&quot;</summary>
        
      
    
    
    
    <category term="深度学习" scheme="https://blog.whff521.xyz/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="Pytorch" scheme="https://blog.whff521.xyz/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>antfu的薅牛毛地图的自用方法</title>
    <link href="https://blog.whff521.xyz/2025/07/14/antfu%E7%9A%84%E8%96%85%E7%89%9B%E6%AF%9B%E5%9C%B0%E5%9B%BE%E7%9A%84%E8%87%AA%E7%94%A8%E6%96%B9%E6%B3%95/"/>
    <id>https://blog.whff521.xyz/2025/07/14/antfu%E7%9A%84%E8%96%85%E7%89%9B%E6%AF%9B%E5%9C%B0%E5%9B%BE%E7%9A%84%E8%87%AA%E7%94%A8%E6%96%B9%E6%B3%95/</id>
    <published>2025-07-14T08:47:56.000Z</published>
    <updated>2025-07-22T07:12:58.101Z</updated>
    
    <content type="html"><![CDATA[<h1 id="antfu的薅牛毛地图的自用方法"><a href="#antfu的薅牛毛地图的自用方法" class="headerlink" title="antfu的薅牛毛地图的自用方法"></a>antfu的薅牛毛地图的自用方法</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>去年看了Anthony Fu的“薅牛毛”演讲，当时看到ppt里密集的路线图着实是被视觉冲击了。将复杂的学习路线通过路线图一个个表示出来，最后整体去俯瞰，竟有一种宏伟的成就感。</p><p>什么是薅牛毛呢？在我的现状下，在学习新东西或者完成任务的时候，难免会有一些“前置知识”需要去了解，然后要理解“前置知识”的话，还需要学习一下“前置知识”的“前置知识”。这可能会变成一种dfs或者bfs，越学越多，越学越远，可能有一天发现自己在草原上薅牛毛，而一开始的目标和薅牛毛没有一点点关联。</p><p>最近正在学习图像识别的内容，最主要的目标就是学会使用YOLOv5。当然仅仅是使用的话很简单，我需要的是了解其中的原理并使用它。也因此我的“薅牛毛”之旅开始了。</p><h2 id="制作方法"><a href="#制作方法" class="headerlink" title="制作方法"></a>制作方法</h2><h3 id="下载代码"><a href="#下载代码" class="headerlink" title="下载代码"></a>下载代码</h3><p>我们可以先fork一下Anthony Fu的<a href="https://github.com/antfu/yak-shaving-map">仓库代码</a>。</p><h3 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h3><p>然后将自己仓库的代码下载到本地，先安装环境：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">如果本地没有pnpm要先下载pnpm，什么？连npm都没有？</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">那可以“薅牛毛”了😂</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">npm install -g pnpm</span></span><br><span class="line">pnpm install</span><br></pre></td></tr></table></figure><p>运行代码只需要运行：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pnpm run dev</span><br></pre></td></tr></table></figure></p><h3 id="修改代码"><a href="#修改代码" class="headerlink" title="修改代码"></a>修改代码</h3><p>其中<code>data.ts</code>中存储的是节点的上下级关系以及节点形状，我们可以删除原来的节点，填写自己想要的节点。</p><p><code>yak-map-pos.json</code>里边是节点的坐标，这个文件不需要手动更改，运行项目后使用鼠标可以拖动节点位置，会自动添加当前节点到json中，json中的节点坐标会自动变化。<strong>建议先把这里面的所有节点删除再添加编写<code>data.ts</code>。</strong></p><p>其中节点类似下面代码：<br><figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">name</span>: <span class="string">&#x27;YOLOv4&#x27;</span>,</span><br><span class="line">  <span class="attr">display</span>: <span class="string">&#x27;YOLOv4&#x27;</span>,</span><br><span class="line">  <span class="attr">link</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">  <span class="attr">shape</span>: <span class="string">&#x27;circle&#x27;</span>,</span><br><span class="line">  <span class="attr">color</span>: colors.<span class="property">YOLOv4</span>,</span><br><span class="line">  <span class="attr">from</span>: [<span class="string">&#x27;yolov5&#x27;</span>],</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">name</span>: <span class="string">&#x27;CSPDarknet53&#x27;</span>,</span><br><span class="line">  <span class="attr">display</span>: <span class="string">&#x27;CSPDarknet53&#x27;</span>,</span><br><span class="line">  <span class="attr">link</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">  <span class="attr">color</span>: colors.<span class="property">YOLOv4</span>,</span><br><span class="line">  <span class="attr">from</span>: [<span class="string">&#x27;YOLOv4&#x27;</span>],</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure></p><p>注意第一个节点要自定义<code>x</code>和<code>y</code>为0。</p><h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h3><p>运行后我们打开网页，界面右上角可以调节暗夜模式，鼠标点击左侧空白是回退，鼠标点击右侧空白是前进，右下角按钮可以进入step模式和展示全部。</p><p>这里附上我制作完成后的页面截图：</p><p><img src="https://images.whff521.top/Screenshot%202025-07-14%20at%2019.41.23.png" alt="yolo map"></p><p>我部署到了Cloudflare的pages上了，方便随时查看。这里附上<a href="https://github.com/WHFF521/yak-shaving-map-yolo">我仓库的链接</a></p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;antfu的薅牛毛地图的自用方法&quot;&gt;&lt;a href=&quot;#antfu的薅牛毛地图的自用方法&quot; class=&quot;headerlink&quot; title=&quot;antfu的薅牛毛地图的自用方法&quot;&gt;&lt;/a&gt;antfu的薅牛毛地图的自用方法&lt;/h1&gt;&lt;h2 id=&quot;背景&quot;&gt;&lt;a</summary>
        
      
    
    
    
    <category term="深度学习" scheme="https://blog.whff521.xyz/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="yolo" scheme="https://blog.whff521.xyz/tags/yolo/"/>
    
    <category term="路线图" scheme="https://blog.whff521.xyz/tags/%E8%B7%AF%E7%BA%BF%E5%9B%BE/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch和cuda环境安装</title>
    <link href="https://blog.whff521.xyz/2025/07/05/Pytorch%E5%92%8Ccuda%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"/>
    <id>https://blog.whff521.xyz/2025/07/05/Pytorch%E5%92%8Ccuda%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/</id>
    <published>2025-07-05T02:09:36.000Z</published>
    <updated>2025-07-05T02:50:23.217Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Pytorch和cuda环境安装"><a href="#Pytorch和cuda环境安装" class="headerlink" title="Pytorch和cuda环境安装"></a>Pytorch和cuda环境安装</h1><p>为了避免更换不同版本Cuda的麻烦，环境在Anaconda里面搭建。</p><h2 id="创建conda环境"><a href="#创建conda环境" class="headerlink" title="创建conda环境"></a>创建conda环境</h2><p>Anaconda的安装就不赘述，首先是创建一个虚拟环境：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create --name your-env-name python=3.13</span><br></pre></td></tr></table></figure><br><code>your-env-name</code>是环境名称，随意更换，python版本也可根据不同环境进行更改。这里要注意<code>--name</code>是两个<code>-</code>，如果只打一个<code>-</code>你有概率会获得一个名字叫<code>ame</code>的虚拟环境😂</p><p>千万不要忘了进入虚拟环境再进行下面的操作：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate your-env-name</span><br></pre></td></tr></table></figure></p><h2 id="安装Cuda"><a href="#安装Cuda" class="headerlink" title="安装Cuda"></a>安装Cuda</h2><p>这里有两种方法，第一是用conda命令进行安装，源应该是conda仓库。第二种是通过pip，源是pip的仓库。其中conda安装的命令虽然更简单，但是conda仓库里Cuda版本十分有限，所以如果conda仓库里如果没有自己想要的版本还是推荐用pip进行安装。</p><h3 id="通过conda安装"><a href="#通过conda安装" class="headerlink" title="通过conda安装"></a>通过conda安装</h3><p>可以通过以下命令查看conda仓库中有哪些版本的Cuda：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda search cudatoolkit --info</span><br></pre></td></tr></table></figure><br>通过conda安装Cuda的命令为：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install cudatoolkit=11.7</span><br></pre></td></tr></table></figure></p><h3 id="通过pip安装"><a href="#通过pip安装" class="headerlink" title="通过pip安装"></a>通过pip安装</h3><p><a href="https://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html#pip-wheels-windows">NVIDIA 官网</a>提供了通过pip安装的方法。</p><p>安装命令如下：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">更新pip</span></span><br><span class="line">py -m pip install --upgrade setuptools pip wheel</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装nvidia-pyindex</span></span><br><span class="line">py -m pip install nvidia-pyindex</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">安装cuda12</span></span><br><span class="line">py -m pip install nvidia-cuda-runtime-cu12</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">可选 安装其他模块</span></span><br><span class="line">py -m pip install nvidia-&lt;library&gt;</span><br></pre></td></tr></table></figure><br>其中<code>py</code>需要替换成<code>python</code>。</p><h2 id="安装Pytorch"><a href="#安装Pytorch" class="headerlink" title="安装Pytorch"></a>安装Pytorch</h2><p><a href="https://pytorch.org/get-started/locally/">Pytorch 官网</a>提供了对应的安装命令<br><img src="https://images.whff521.top/Screenshot%202025-07-05%20at%2010.35.01.png" alt="安装命令"></p><p>这里贴出我使用的：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118</span><br></pre></td></tr></table></figure></p><h2 id="检验安装"><a href="#检验安装" class="headerlink" title="检验安装"></a>检验安装</h2><p>直接在命令行中输入<code>python</code>进入到python，输入以下几行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(torch.version.cuda)</span><br><span class="line">torch.cuda.is_available()</span><br></pre></td></tr></table></figure><p>注意import之后会有一段时间等待python加载。</p><p>PS：今天也是我第一次用anaconda进行搭建这个环境，仅仅是搭建还未投入到代码的使用，可能会有问题。</p><p>PS2：封面是大空スバル，两天前是她的生日！しゅばしゅばしゅば！！！ </p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;Pytorch和cuda环境安装&quot;&gt;&lt;a href=&quot;#Pytorch和cuda环境安装&quot; class=&quot;headerlink&quot;</summary>
        
      
    
    
    
    <category term="深度学习" scheme="https://blog.whff521.xyz/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="Pytorch" scheme="https://blog.whff521.xyz/tags/Pytorch/"/>
    
    <category term="Cuda" scheme="https://blog.whff521.xyz/tags/Cuda/"/>
    
  </entry>
  
</feed>
